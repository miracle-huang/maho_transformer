{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ取得関数(ファイル名、取得したいデータ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def get_data(filename, want):\n",
    "    data = loadmat(filename)\n",
    "    return data[want]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nanがあるか確認\n",
    "`np.isnan`:用于检查数组中的每个元素是否是 NaN\n",
    "\n",
    "这里是检查是否有空值\n",
    "\n",
    "如果有空值的话，后面处理过程中跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant:9 video:0\n",
      "participant:9 video:1\n",
      "participant:9 video:2\n",
      "participant:9 video:5\n",
      "participant:9 video:6\n",
      "participant:9 video:8\n",
      "participant:9 video:10\n",
      "participant:9 video:11\n",
      "participant:9 video:12\n",
      "participant:9 video:14\n",
      "participant:9 video:15\n",
      "participant:12 video:4\n",
      "participant:17 video:18\n",
      "participant:18 video:19\n",
      "participant:21 video:1\n",
      "participant:21 video:10\n",
      "participant:22 video:15\n",
      "participant:22 video:18\n",
      "participant:23 video:0\n",
      "participant:23 video:4\n",
      "participant:23 video:6\n",
      "participant:23 video:8\n",
      "participant:23 video:11\n",
      "participant:24 video:0\n",
      "participant:24 video:7\n",
      "participant:24 video:11\n",
      "participant:24 video:12\n",
      "participant:24 video:13\n",
      "participant:24 video:14\n",
      "participant:24 video:15\n",
      "participant:33 video:0\n",
      "participant:33 video:1\n",
      "participant:33 video:2\n",
      "participant:33 video:6\n",
      "participant:33 video:7\n",
      "participant:33 video:8\n",
      "participant:33 video:9\n",
      "participant:33 video:10\n",
      "participant:33 video:12\n",
      "participant:33 video:15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for x in range(1, 41):\n",
    "    if x < 10:\n",
    "        l = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x) + \"/Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "    else:\n",
    "        l = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x) + \"/Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "    \n",
    "    for i in range(0, 20):\n",
    "        # print(l[0][x].shape)\n",
    "        if np.isnan(l[0][i]).any() == True:\n",
    "            print(f\"participant:{x} video:{i}\")\n",
    "    \n",
    "    \n",
    "    # for i in range(0, len(l)):\n",
    "    #     if np.isnan(l[i]).any() == True:\n",
    "    #         print(\"P\" + str(x) + \" \" + str(i))\n",
    "\n",
    "# l = get_data(\"Data_Preprocessed_P40\", \"joined_data\")\n",
    "#print(len(l[0]))\n",
    "\n",
    "# for x in range(0, 20):\n",
    "    #print(x)\n",
    "    #print(l[0][x])\n",
    "    #print(np.isnan(l[0][x][:, 16]))\n",
    "    # if np.isnan(l[0][x][:, 0]).any() == True:\n",
    "        # print(x) #14, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 40 # 作成するデータセットの被験者数\n",
    "segment_sec = 10 #ウィンドウサイズ\n",
    "slide_sec = 5 #スライディングウィンドウサイズ\n",
    "kind_of_label = 0 #覚醒度(0)か感情価(1)か\n",
    "index = 0 #取得位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将 labeldata 中 n 个视频的 f 列标签值添加到 appendlist 中\n",
    "# def append_label(appendlist, labeldata, n, f): #n:加える動画数、f:ラベル内容\n",
    "#     for x in range(n):\n",
    "#         appendlist.append(labeldata[0][x][0][f])\n",
    "\n",
    "# # 向 appendlist 添加 labeldata 中第 n 个视频的 f 列标签值。\n",
    "# def append_1label(appendlist, labeldata, n, f): #n:加える動画番号、f:ラベル内容\n",
    "#     appendlist.append(labeldata[0][n][0][f])\n",
    "\n",
    "# label_list = []\n",
    "# for x in range(1, num + 1):\n",
    "#     if x < 10:\n",
    "#         labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "#         if x == 8:\n",
    "#             append_label(label_list, labeldata, 16, kind_of_label)\n",
    "#         #elif x == 9:\n",
    "#         #    for n in range(0, 17):\n",
    "#         #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "#         #            append_1label(label_list, labeldata, n, kind_of_label)      \n",
    "#         else:\n",
    "#             append_label(label_list, labeldata, 20, kind_of_label)\n",
    "#     else:\n",
    "#         labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "#         if x == 24 or x == 28 or x == 32:\n",
    "#             append_label(label_list, labeldata, 16, kind_of_label)\n",
    "#         else:\n",
    "#             append_label(label_list, labeldata, 20, kind_of_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有非空实验的label全部放到一个list当中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_label(appendlist, labeldata, n, f): #n:加える動画数、f:ラベル内容\n",
    "    for x in range(n):\n",
    "        appendlist.append(labeldata[0][x][0][f])\n",
    "\n",
    "def append_1label(appendlist, labeldata, n, f): #n:加える動画番号、f:ラベル内容\n",
    "    appendlist.append(labeldata[0][n][0][f])\n",
    "\n",
    "label_list = []\n",
    "for x in range(1, num + 1):\n",
    "    if x < 10:\n",
    "        labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x) + \"/Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            append_label(label_list, labeldata, 16, kind_of_label)\n",
    "        #elif x == 9:\n",
    "        #    for n in range(0, 17):\n",
    "        #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "        #            append_1label(label_list, labeldata, n, kind_of_label)      \n",
    "        else:\n",
    "            append_label(label_list, labeldata, 20, kind_of_label)\n",
    "    else:\n",
    "        labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x) + \"/Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 28 or x == 32:\n",
    "            append_label(label_list, labeldata, 16, kind_of_label)\n",
    "        elif x == 12:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 4:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 17:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 18:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 18:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 19:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 21:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 1 or n == 10):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 22:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 15 or n == 18):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 23:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 0 or n == 4 or n == 6 or n == 8 or n == 11):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 24:\n",
    "            for n in range(0, 11):\n",
    "                if not (n == 0 or n == 7):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 33:\n",
    "            for n in range(3, 20):\n",
    "                if not (n == 6 or n == 7 or n == 8 or n == 9 or n == 10 or n == 12 or n == 15):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        else:\n",
    "            append_label(label_list, labeldata, 20, kind_of_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.199635592052985\n"
     ]
    }
   ],
   "source": [
    "average = sum(label_list) / len(label_list)\n",
    "print(average)\n",
    "\n",
    "#被験者40人、覚醒度：5.247849085271323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルデータ取得関数(ファイル名、シート名、取得したい被験者番号、評価の種類)　（処理済みデータには使用しない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "def get_rabel(file_name, sheet_name, subject_no, n): #n:取得したい評価の種類の列\n",
    "    w = openpyxl.load_workbook(file_name)\n",
    "    sheet = w.get_sheet_by_name(sheet_name)\n",
    "    rabel = []\n",
    "    for i in range(16 * (subject_no - 1) + 3, 16 * (subject_no - 1) + 19):\n",
    "        rabel.append(sheet.cell(row = i, column = n).value)\n",
    "    return rabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2値分類変更関数(2値分類前のラベルデータ)\n",
    "\n",
    "根据给定的阈值把label分为0和1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2rabel(label_data):\n",
    "    label_2 = []\n",
    "    ave = sum(label_data) / len(label_data)\n",
    "    for i in range(0, len(label_data)):\n",
    "        if label_data[i] <= ave:\n",
    "            label_2.append(0)\n",
    "        else:\n",
    "            label_2.append(1)\n",
    "    return label_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成関数覚醒度のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#w=ウィンドウサイズ、s=ずらす秒数\n",
    "def create_dataset(signal_data, rabel_data, video_no, w, s, index):\n",
    "    fs = 128  # sampling周波数  \n",
    "    end_sample = len(signal_data[0][video_no][:, index])\n",
    "\n",
    "    segmentations = []\n",
    "    for idx in range(0, end_sample, int(fs*s)):\n",
    "        segment_len = fs * w  # セグメント長さ\n",
    "        segment = signal_data[0][video_no][idx:idx+(fs*w), index]  # セグメント\n",
    "        if len(segment) == segment_len:\n",
    "            segmentations.append(segment)\n",
    "\n",
    "    rabels = np.array([rabel_data[video_no]] * len(segmentations)) \n",
    "\n",
    "    return segmentations, rabels \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辞書化データセット保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def write_pickle(segmentations_data, rabels_data, file_name):\n",
    "    dataset_dic = {\n",
    "        \"x\" : segmentations_data,\n",
    "        \"y\" : rabels_data,\n",
    "    }\n",
    "    with open(\"./dataset/\" + file_name + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(dataset_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15610\n",
      "-14.156861732467481\n",
      "[[2.938568 5.       8.235496 1.       1.       1.       0.       0.\n",
      "  0.       0.       0.       0.      ]]\n",
      "3.72\n"
     ]
    }
   ],
   "source": [
    "# 打印数据集的shape并观察数据集的形状\n",
    "# 每一个文件代表一个participant\n",
    "# 每个文件当中有20个矩阵，每个矩阵代表一个video\n",
    "# 每个矩阵当中有17列，每列代表一个channel\n",
    "# 所有的数据被降采样到128Hz\n",
    "# joined_data.shape: (20video, 17channel, 数据量)\n",
    "# labels_selfassessment.shape: (20video, 1*12label)\n",
    "# 每个label对应一种情感，每个情感的取值范围是0-10\n",
    "# 1 x label (arousal, valence, dominance, liking, familiarity, neutral, disgust,happiness, surprise, anger, fear, and sadness) for trial YY\n",
    "\n",
    "ecgdata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P01/Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P01/Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "\n",
    "# ecgdata[0][2][:, 0]：从 ecgdata[0][1] 中提取出第 0 列的所有元素，返回一个一维数组。\n",
    "# 这个一维数组的长度取决于视频的长度\n",
    "print(len(ecgdata[0][2][:, 0]))\n",
    "print(ecgdata[0][0][1][15])\n",
    "\n",
    "\n",
    "print(labeldata[0][0])\n",
    "print(labeldata[0][19][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2値のラベル取得(ラベルデータ、平均値)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(labeldata, ave):\n",
    "    if labeldata > ave:\n",
    "        return 1\n",
    "    elif labeldata <= ave:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット取得(処理済データ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1つの動画のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def make_dataset(signaldata, labeldata, ave, segment_sec, slide, n, f, l): \n",
    "    # signaldata-信号データ\n",
    "    # labeldata-ラベルデータ\n",
    "    # ave-ラベルの平均値\n",
    "    # segment_sec-セグメント長\n",
    "    # slide-スライディングウィンドウサイズ\n",
    "    # n-動画番号\n",
    "    # f-取得位置\n",
    "    # l-覚醒度:0感情価1 1動画当たり\n",
    "    fs = 128 #サンプリング周波数 128Hz\n",
    "    end_sample = len(signaldata[0][n][:, f]) #取得したいデータのデータの数c\n",
    "    label = get_label(labeldata[0][n][0][l], ave) #平均値を閾値としたラベル取得(2値)\n",
    "    div_signals = [] #ここにセグメント分割された信号データを入れる\n",
    "\n",
    "    for idx in range(0, end_sample, int(fs * slide)): #信号データの分割\n",
    "        #mult_position = [] #取得位置を複数にしたいから\n",
    "        segment_len = fs * segment_sec #セグメントの長さ\n",
    "        for t in n:\n",
    "            \n",
    "            segment = signaldata[0][n][idx : idx + (fs * segment_sec), f] #分割された信号データ\n",
    "            #segment2 = signaldata[0][0][idx : idx + (fs * segment_sec), f + 1] #分割された信号データ\n",
    "            #mult_position.append(segment)\n",
    "            #mult_position.append(segment2)\n",
    "        if len(segment) == segment_len:\n",
    "            div_signals.append(segment) #mult_position\n",
    "    \n",
    "    labels = np.array([label] * len(div_signals))\n",
    "    return div_signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特定の一つの動画のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_specdataset(signaldata, labeldata, ave, segment, slide, f, l, n):#(信号データ、ラベルデータ、ラベルの平均値、セグメント長、スライディングウィンドウサイズ、取得位置、覚醒度:0感情価1、動画no) 1動画当たり\n",
    "    signals, labels = make_dataset(signaldata, labeldata, ave, segment, slide, n, f, l)\n",
    "    return signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1人のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_P1dataset(signaldata, labeldata, ave, segment, slide, f, l, endno): #(信号データ、ラベルデータ、ラベルの平均値、セグメント長、スライディングウィンドウサイズ、取得位置、覚醒度:0感情価1、動画数16or20) 1動画当たり\n",
    "    # signaldata-信号データ\n",
    "    # labeldata-ラベルデータ\n",
    "    # ave-ラベルの平均値\n",
    "    # segment-セグメント長\n",
    "    # slide-スライディングウィンドウサイズ\n",
    "    # f-取得位置\n",
    "    # l-覚醒度:0感情価1\n",
    "    # endno-動画数16or20\n",
    "    signals, labels = make_dataset(signaldata, labeldata, ave, segment, slide, 0, f, l)\n",
    "    for x in range(1, endno):\n",
    "        signal, label = make_dataset(signaldata, labeldata, ave, segment, slide, x, f, l)\n",
    "        signals = np.concatenate([signals, signal])\n",
    "        labels = np.concatenate([labels, label])\n",
    "    return signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44216, 1280)\n",
      "(44216,)\n"
     ]
    }
   ],
   "source": [
    "signaldata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "signal_datas, label_datas = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "\n",
    "for x in range(2, num + 1):\n",
    "    if x < 10:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "    else:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 28 or x == 32:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 12:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 4:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 17:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 18:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 18:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 19:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 21:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 1 or n == 10):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 22:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 15 or n == 18):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 23:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 0 or n == 4 or n == 6 or n == 8 or n == 11):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 24:\n",
    "            for n in range(0, 11):\n",
    "                if not (n == 0 or n == 7):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 33:\n",
    "            for n in range(3, 20):\n",
    "                if not (n == 6 or n == 7 or n == 8 or n == 9 or n == 10 or n == 12 or n == 15):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "\n",
    "print(signal_datas.shape)\n",
    "print(label_datas.shape)\n",
    "write_pickle(signal_datas, label_datas, \"10sproceedsubjectsP40EEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45408, 1280)\n",
      "(45408,)\n"
     ]
    }
   ],
   "source": [
    "signaldata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "signal_datas, label_datas = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "\n",
    "for x in range(2, num + 1):\n",
    "    if x < 10:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        #elif x == 9: ECGのみ\n",
    "        #    for n in range(0, 20):\n",
    "        #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "        #            print(n)\n",
    "        #            signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "        #            signal_datas = np.concatenate([signal_datas, signal])\n",
    "        #            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "    else:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 24 or x == 28 or x == 32:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "\n",
    "print(signal_datas.shape)\n",
    "print(label_datas.shape)\n",
    "write_pickle(signal_datas, label_datas, \"10sproceedsubjectsP40GSR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#google colabのとき↓\n",
    "    #/content/drive/MyDrive/dataset/\n",
    "#研究室PCのとき↓\n",
    "#/Users/Ma-Lab-PC3/SatoMaho/\n",
    "\n",
    "def read_pickle(file_name):\n",
    "    with open(\"/Users/admin/卒業研究/CNN/dataset/\" + file_name + \".pickle\", \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "    return dic[\"x\"], dic[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44216, 1280)\n",
      "(45211, 1280)\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "w, z = read_pickle(\"10sproceedsubjectsP40EEG\")\n",
    "p, q = read_pickle(\"10sproceedsubjectsP40\")\n",
    "print(w.shape)\n",
    "print(p.shape)\n",
    "for x in range(0, 20):\n",
    "    print(z[x * 100], q[x * 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mread_pickle\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5sproceedsubjectsP40\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_pickle' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = read_pickle(\"5sproceedsubjectsP40\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m ecgdata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m labeldata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_selfassessment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m segmentations_datas, labels_datas \u001b[38;5;241m=\u001b[39m \u001b[43mmake_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecgdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeldata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor i in range(2,6):\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mwrite_pickle(segmentations_datas, np.array(label_2), ave, \"5sproceedsubjects1-16P20\")\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mmake_datasets\u001b[1;34m(signaldata, labeldata)\u001b[0m\n\u001b[0;32m     23\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labeldata[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(segmentations))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#データを取得してリスト化\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     segmentations_data, labels_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m(signaldata, label_datas, \u001b[38;5;241m0\u001b[39m, segment_sec, slide_sec, index) \u001b[38;5;66;03m#最初だけ単体で作ってそこに入れてく\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#segmentations_data, labels_data = create_dataset(signaldata, label_datas_2, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m): \u001b[38;5;66;03m#動画番号\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#データセットリスト作成\n",
    "def make_datasets(signaldata, labeldata):\n",
    "    segment_sec = 5  # ウィンドウの秒数\n",
    "    slide_sec = 2.5  # ずらす秒数\n",
    "    fs = 128  # sampling周波数  \n",
    "    index = 14 #取得したいデータ\n",
    "    end_sample = len(signaldata[0][0][:, index])\n",
    "\n",
    "    label_datas = []\n",
    "\n",
    "    for i in range(0, 19):\n",
    "        label_datas.append(labeldata[0][i][0][0])\n",
    "\n",
    "    #label_datas_2 = make_2rabel(label_datas) #2値分類\n",
    "\n",
    "    segmentations = []\n",
    "    for idx in range(0, end_sample, int(fs*slide_sec)):\n",
    "        segment_len = fs * segment_sec  # セグメント長さ\n",
    "        segment = signaldata[0][0][idx:idx+(fs*segment_sec), index]  # セグメント\n",
    "        if len(segment) == segment_len:\n",
    "            segmentations.append(segment)\n",
    "\n",
    "    labels = np.array([labeldata[0]] * len(segmentations))\n",
    "#データを取得してリスト化\n",
    "    segmentations_data, labels_data = create_dataset(signaldata, label_datas, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\n",
    "    #segmentations_data, labels_data = create_dataset(signaldata, label_datas_2, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\n",
    "    for i in range(1, 16): #動画番号\n",
    "        x, y = create_dataset(signaldata, label_datas, i, segment_sec, slide_sec, index)\n",
    "        #x, y = create_dataset(signaldata, label_datas_2, i, segment_sec, slide_sec, index)\n",
    "        segmentations_data = np.concatenate([segmentations_data, x])\n",
    "        labels_data = np.concatenate([labels_data, y])\n",
    "    print(len(segmentations_data), len(labels_data))\n",
    "\n",
    "    return segmentations_data, labels_data\n",
    "\n",
    "ecgdata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "\n",
    "segmentations_datas, labels_datas = make_datasets(ecgdata, labeldata)\n",
    "\"\"\"\n",
    "for i in range(2,6):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P0\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(10,11):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(19,21):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(25,28):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "#正規化\n",
    "def min_max(label):\n",
    "    l_min = min(label)\n",
    "    l_max = max(label)\n",
    "    return [(i - l_min) / (l_max - l_min) for i in label]\n",
    "\n",
    "scalsed_labels = min_max(labels_datas)\n",
    "#print(scalsed_labels)\n",
    "\n",
    "ave = sum(scalsed_labels) / len(scalsed_labels) #閾値\n",
    "#print(ave)\n",
    "\n",
    "label_2 = []\n",
    "for i in range(0, len(scalsed_labels)):\n",
    "    if scalsed_labels[i] <= ave:\n",
    "        label_2.append(0)\n",
    "    else:\n",
    "        label_2.append(1)\n",
    "#print(label_2)\n",
    "write_pickle(segmentations_datas, np.array(label_2), ave, \"5sproceedsubjects1-16P20\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_ldata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ecgdata \u001b[38;5;241m=\u001b[39m \u001b[43mget_ldata\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m labeldata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_selfassessment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m segmentations_datas, labels_datas \u001b[38;5;241m=\u001b[39m make_datasets(ecgdata, labeldata)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_ldata' is not defined"
     ]
    }
   ],
   "source": [
    "ecgdata = get_ldata(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "\n",
    "segmentations_datas, labels_datas = make_datasets(ecgdata, labeldata)\n",
    "for i in range(2,3):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P0\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "print(segmentations_datas)\n",
    "print(labels_datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
