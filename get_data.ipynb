{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ取得関数(ファイル名、取得したいデータ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "def get_data(filename, want):\n",
    "    data = loadmat(filename)\n",
    "    return data[want]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nanがあるか確認\n",
    "`np.isnan`:用于检查数组中的每个元素是否是 NaN\n",
    "\n",
    "这里是检查是否有空值\n",
    "\n",
    "如果有空值的话，后面处理过程中跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant:9 video:0\n",
      "participant:9 video:1\n",
      "participant:9 video:2\n",
      "participant:9 video:5\n",
      "participant:9 video:6\n",
      "participant:9 video:8\n",
      "participant:9 video:10\n",
      "participant:9 video:11\n",
      "participant:9 video:12\n",
      "participant:9 video:14\n",
      "participant:9 video:15\n",
      "participant:12 video:4\n",
      "participant:17 video:18\n",
      "participant:18 video:19\n",
      "participant:21 video:1\n",
      "participant:21 video:10\n",
      "participant:22 video:15\n",
      "participant:22 video:18\n",
      "participant:23 video:0\n",
      "participant:23 video:4\n",
      "participant:23 video:6\n",
      "participant:23 video:8\n",
      "participant:23 video:11\n",
      "participant:24 video:0\n",
      "participant:24 video:7\n",
      "participant:24 video:11\n",
      "participant:24 video:12\n",
      "participant:24 video:13\n",
      "participant:24 video:14\n",
      "participant:24 video:15\n",
      "participant:33 video:0\n",
      "participant:33 video:1\n",
      "participant:33 video:2\n",
      "participant:33 video:6\n",
      "participant:33 video:7\n",
      "participant:33 video:8\n",
      "participant:33 video:9\n",
      "participant:33 video:10\n",
      "participant:33 video:12\n",
      "participant:33 video:15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for x in range(1, 41):\n",
    "    if x < 10:\n",
    "        l = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x) + \"/Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "    else:\n",
    "        l = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x) + \"/Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "    \n",
    "    for i in range(0, 20):\n",
    "        # print(l[0][x].shape)\n",
    "        if np.isnan(l[0][i]).any() == True:\n",
    "            print(f\"participant:{x} video:{i}\")\n",
    "    \n",
    "    \n",
    "    # for i in range(0, len(l)):\n",
    "    #     if np.isnan(l[i]).any() == True:\n",
    "    #         print(\"P\" + str(x) + \" \" + str(i))\n",
    "\n",
    "# l = get_data(\"Data_Preprocessed_P40\", \"joined_data\")\n",
    "#print(len(l[0]))\n",
    "\n",
    "# for x in range(0, 20):\n",
    "    #print(x)\n",
    "    #print(l[0][x])\n",
    "    #print(np.isnan(l[0][x][:, 16]))\n",
    "    # if np.isnan(l[0][x][:, 0]).any() == True:\n",
    "        # print(x) #14, 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 40 # 作成するデータセットの被験者数\n",
    "segment_sec = 10 #ウィンドウサイズ\n",
    "slide_sec = 5 #スライディングウィンドウサイズ\n",
    "kind_of_label = 0 #覚醒度(0)か感情価(1)か\n",
    "index = 0 #取得位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将 labeldata 中 n 个视频的 f 列标签值添加到 appendlist 中\n",
    "# def append_label(appendlist, labeldata, n, f): #n:加える動画数、f:ラベル内容\n",
    "#     for x in range(n):\n",
    "#         appendlist.append(labeldata[0][x][0][f])\n",
    "\n",
    "# # 向 appendlist 添加 labeldata 中第 n 个视频的 f 列标签值。\n",
    "# def append_1label(appendlist, labeldata, n, f): #n:加える動画番号、f:ラベル内容\n",
    "#     appendlist.append(labeldata[0][n][0][f])\n",
    "\n",
    "# label_list = []\n",
    "# for x in range(1, num + 1):\n",
    "#     if x < 10:\n",
    "#         labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "#         if x == 8:\n",
    "#             append_label(label_list, labeldata, 16, kind_of_label)\n",
    "#         #elif x == 9:\n",
    "#         #    for n in range(0, 17):\n",
    "#         #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "#         #            append_1label(label_list, labeldata, n, kind_of_label)      \n",
    "#         else:\n",
    "#             append_label(label_list, labeldata, 20, kind_of_label)\n",
    "#     else:\n",
    "#         labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "#         if x == 24 or x == 28 or x == 32:\n",
    "#             append_label(label_list, labeldata, 16, kind_of_label)\n",
    "#         else:\n",
    "#             append_label(label_list, labeldata, 20, kind_of_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将所有非空实验的label全部放到一个list当中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.938568, 4.877136, 5.0, 2.965872, 6.460752, 5.0, 6.488055999999999, 9.0, 1.382256, 6.6, 6.542664, 4.931744, 6.488055999999999, 5.0, 4.959048, 3.129696, 7.88, 6.36, 6.36, 1.8, 1, 9, 4.90444, 2.88396, 3.211608, 5.122864, 4.877136, 5.0, 5.0, 5.0, 6.733792, 6.6, 6.65188, 4.986352, 2.993176, 4.877136, 6.28, 6.44, 5.0, 3.48, 1.60068, 3.2389040000000002, 2.665528, 3.730376, 1.191128, 5.341296, 4.058024, 3.784984, 6.133104, 5.532424, 6.078496, 3.976112, 6.7884, 1.627984, 7.225256, 3.539248, 5.8, 2.92, 6.12, 3.96, 3.02048, 2.965872, 6.023888, 1.0, 6.160408, 6.924912, 6.160408, 6.924912, 6.815696, 6.296928, 7.607512, 5.614336, 6.679184, 5.0, 6.133104, 6.078496, 6.2, 5.0, 5.48, 5.56, 5.696248000000001, 6.269623999999999, 6.433448, 5.395904, 6.870304, 7.361776, 7.143344, 7.8259360000000004, 7.034128, 6.51536, 9.0, 9.0, 7.7986320000000005, 6.351536, 6.7884, 6.187712, 8.2, 6.04, 7.16, 5.8, 1.627984, 3.866896, 5.477816000000001, 6.65188, 3.075088, 4.822528, 5.668944000000001, 5.914672, 6.37884, 5.887376000000001, 5.914672, 7.6894160000000005, 7.416384000000001, 5.696248000000001, 6.924912, 8.672352, 7.64, 7.8, 6.36, 6.2, 1.5187680000000001, 1.354952, 3.184304, 1.901024, 5.64164, 6.269623999999999, 4.249144, 5.723552000000001, 6.269623999999999, 5.887376000000001, 2.501704, 6.51536, 6.296928, 5.77816, 6.733792, 7.771328, 7.8, 7.56, 6.28, 5.56, 6.569968, 5.0, 3.075088, 6.460752, 5.0, 7.006824, 5.941976, 7.11604, 6.51536, 5.532424, 8.126280000000001, 7.361776, 4.877136, 4.194536, 6.706488, 5.8, 2.447096, 1.4641600000000001, 1.354952, 1.87372, 1.054608, 2.310584, 3.648464, 5.0, 7.307168, 6.761096, 6.0511919999999995, 5.150168, 6.897608, 4.440272, 6.215016, 5.204776, 7.8, 2.76, 4.04, 5.08, 3.02048, 2.665528, 2.064848, 1.655288, 2.74744, 3.129696, 3.430032, 6.37884, 5.0, 3.102392, 4.90444, 3.129696, 2.4744, 2.583616, 4.931744, 1.0, 4.92, 1.24, 2.04, 2.36, 2.965872, 3.02048, 3.075088, 2.88396, 3.02048, 3.075088, 3.02048, 2.911264, 2.938568, 2.856656, 1.109216, 3.375424, 3.129696, 3.102392, 3.047784, 2.829352, 1.0, 1.0, 1.0, 1.0, 3.129696, 2.61092, 1.218432, 3.047784, 5.0, 7.088736, 8.044368, 7.66212, 7.307168, 7.197952000000001, 6.24232, 7.880544, 3.211608, 5.0, 7.061432, 7.96, 6.2, 7.0, 4.92, 5.696248000000001, 5.559728, 3.839592, 4.412968, 3.839592, 4.604096, 6.269623999999999, 7.98976, 6.269623999999999, 6.24232, 7.7986320000000005, 5.941976, 6.324232, 5.750856, 6.215016, 6.679184, 5.96, 6.52, 7.72, 3.72, 4.412968, 3.948808, 5.64164, 4.249144, 4.358359999999999, 3.730376, 4.331056, 6.870304, 6.187712, 5.450512000000001, 7.006824, 4.249144, 4.331056, 4.139927999999999, 3.62116, 5.559728, 6.12, 6.6, 6.52, 3.32, 3.593856, 1.8, 3.8942, 4.2, 5.0, 2.3378880000000004, 3.8942, 7.4, 4.959048, 5.0, 6.078496, 5.0, 5.8, 5.0, 6.6, 6.6, 5.64, 6.52, 5.72, 4.76, 6.597272, 4.90444, 4.849832, 6.542664, 2.993176, 6.51536, 6.542664, 8.699656000000001, 6.51536, 4.849832, 6.733792, 6.679184, 6.542664, 4.877136, 6.597272, 6.597272, 6.36, 3.48, 6.44, 4.84, 7.443688000000001, 2.310584, 2.856656, 2.856656, 3.566552, 1.819112, 3.457336, 8.2628, 6.706488, 3.2662080000000002, 7.880544, 4.194536, 6.979520000000001, 2.255976, 6.433448, 1.60068, 6.76, 1.64, 1.88, 3.047784, 5.860072, 5.0, 2.14676, 3.457336, 6.7884, 3.457336, 7.498296, 6.979520000000001, 5.750856, 7.6894160000000005, 6.406144, 5.941976, 3.784984, 6.0511919999999995, 6.215016, 6.52, 6.44, 6.52, 3.457336, 1.928328, 4.440272, 3.703072, 4.331056, 5.887376000000001, 4.522184, 6.488055999999999, 6.65188, 5.013648, 6.460752, 6.0511919999999995, 5.914672, 6.269623999999999, 5.941976, 5.805464, 6.84, 8.12, 6.84, 6.68, 2.6, 3.4, 3.4, 2.6, 3.4, 4.2, 3.4, 6.6, 3.4, 3.4, 5.0, 2.6, 4.2, 3.4, 5.8, 4.2, 4.6, 3.08, 3.8, 4.2, 3.184304, 1.982936, 1.982936, 6.6, 6.542664, 5.450512000000001, 7.034128, 7.7986320000000005, 4.959048, 8.617744, 8.017064, 3.730376, 8.317408, 6.6, 7.88, 8.28, 5.88, 2.12, 5.750856, 5.64164, 6.215016, 4.058024, 6.187712, 6.542664, 7.25256, 6.979520000000001, 7.225256, 5.450512000000001, 6.597272, 6.133104, 6.351536, 5.286688, 6.460752, 6.28, 6.04, 6.68, 5.0, 5.0, 3.129696, 6.761096, 6.733792, 6.624576, 6.433448, 6.624576, 6.952216, 4.90444, 6.597272, 6.36, 4.92, 6.52, 7.32, 5.420336, 5.284744, 5.8, 6.694912, 5.8, 5.8, 7.237288, 8.94576, 8.2, 5.989832, 5.0, 6.3694880000000005, 4.444064, 5.393224, 5.610168, 3.6847440000000002, 6.6678, 6.342376, 6.5593200000000005, 7.210168, 6.5864400000000005, 6.152544, 2.9796639999999996, 4.579663999999999, 5.0, 7.64, 4.2, 6.36, 5.96, 3.061016, 2.301696, 6.5322, 3.6033920000000004, 6.477968, 6.044072, 7.42712, 7.589832, 7.508472, 6.071184000000001, 8.864408000000001, 7.183048, 6.694912, 5.0, 4.064408, 6.315256, 7.96, 5.0, 7.48, 3.24, 5.88136, 2.62712, 5.0, 5.0, 3.928816, 5.0, 6.477968, 7.4, 6.640680000000001, 5.0, 6.803392, 6.5864400000000005, 4.037288, 5.908472, 6.6678, 6.8576239999999995, 5.56, 3.8, 3.4, 2.04, 7.833896000000001, 6.2067760000000005, 5.0, 6.694912, 6.342376, 5.0, 6.016952000000001, 6.5322, 8.267800000000001, 5.0, 6.288136, 6.152544, 6.5864400000000005, 5.0, 5.0, 5.0, 3.277968, 6.423728, 3.35932, 6.5322, 2.0576239999999997, 5.0, 6.5864400000000005, 6.6678, 3.142376, 6.9661040000000005, 7.888136, 1.4610159999999999, 5.0, 6.640680000000001, 6.7491520000000005, 7.155936, 7.72, 1.96, 6.68, 6.6, 2.5186479999999998, 3.901696, 2.54576, 2.410168, 1.922032, 1.596608, 3.088136, 3.8745760000000002, 2.898304, 3.223728, 2.844064, 3.115256, 2.9254240000000005, 2.437288, 3.766104, 3.142376, 3.32, 3.48, 2.12, 3.32, 6.016952000000001, 6.342376, 3.1966080000000003, 5.85424, 7.3186480000000005, 6.694912, 6.803392, 8.511864, 7.833896000000001, 6.5864400000000005, 6.505088000000001, 7.3186480000000005, 5.88136, 5.718648, 6.803392, 7.020336, 7.12, 5.08, 5.08, 3.04, 4.823728, 5.0, 5.0, 5.0, 5.0, 5.0, 4.823728, 6.233896, 5.257624, 4.850848000000001, 5.366104, 3.4135600000000004, 5.338984, 5.284744, 5.230512, 5.772880000000001, 5.0, 4.715256, 5.0, 6.61356, 1.0, 6.911864, 7.12, 7.12, 7.12, 6.64, 1.0, 1.6237279999999998, 2.193224, 1.705088, 3.115256, 7.101696, 3.35932, 9, 6.6678, 6.179664, 6.152544, 6.044072, 2.9525439999999996, 6.640680000000001, 3.711864, 4.091528, 5.96, 6.12, 6.2, 6.52, 2.7355920000000005, 7.942375999999999, 3.061016, 2.6, 3.1694880000000003, 8.050847999999998, 3.223728, 5.0, 6.6, 6.8576239999999995, 8.159320000000001, 3.3322, 6.261016000000001, 2.6, 4.877968, 6.288136, 6.52, 6.28, 4.84, 7.4, 6.8576239999999995, 3.088136, 4.796608, 5.908472, 5.0, 3.4135600000000004, 5.0, 6.803392, 5.0, 5.0, 6.423728, 5.0, 6.477968, 5.0, 6.477968, 5.0, 7.48, 6.84, 6.92, 5.88, 3.576272, 3.7932240000000004, 3.7932240000000004, 2.166104, 3.549152, 3.549152, 3.522032, 6.5864400000000005, 5.664408, 3.35932, 5.474576, 3.1694880000000003, 5.88136, 1.488136, 2.844064, 6.2067760000000005, 5.96, 3.48, 4.2, 3.4, 5.0, 5.094912, 3.522032, 3.4, 3.4, 5.8, 3.4, 8.593224, 6.071184000000001, 6.125424, 7.34576, 6.803392, 8.2, 1.379664, 2.193224, 5.74576, 6.2, 7.4, 4.84, 5.48, 3.061016, 3.1694880000000003, 3.576272, 3.1966080000000003, 3.8745760000000002, 3.928816, 6.233896, 6.6678, 5.908472, 6.9661040000000005, 6.993224, 5.908472, 6.071184000000001, 3.088136, 4.037288, 5.74576, 8.76, 5.88, 5.0, 3.0, 5, 7.020336, 5.0, 3.928816, 5, 6.152544, 5, 7.589832, 5.501696, 6.098304, 6.884744, 6.044072, 6.342376, 5.0, 5.555936, 6.450848000000001, 6.04, 3.24, 6.28, 6.92]\n",
      "755\n"
     ]
    }
   ],
   "source": [
    "def append_label(appendlist, labeldata, n, f): #n:加える動画数、f:ラベル内容\n",
    "    for x in range(n):\n",
    "        appendlist.append(labeldata[0][x][0][f])\n",
    "\n",
    "def append_1label(appendlist, labeldata, n, f): #n:加える動画番号、f:ラベル内容\n",
    "    appendlist.append(labeldata[0][n][0][f])\n",
    "\n",
    "label_list = []\n",
    "for x in range(1, num + 1):\n",
    "    if x < 10:\n",
    "        labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P0\" + str(x) + \"/Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            append_label(label_list, labeldata, 16, kind_of_label)\n",
    "        #elif x == 9:\n",
    "        #    for n in range(0, 17):\n",
    "        #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "        #            append_1label(label_list, labeldata, n, kind_of_label)      \n",
    "        else:\n",
    "            append_label(label_list, labeldata, 20, kind_of_label)\n",
    "    else:\n",
    "        labeldata = get_data(\"amigo/data_preprocessed/Data_Preprocessed_P\" + str(x) + \"/Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 28 or x == 32:\n",
    "            append_label(label_list, labeldata, 16, kind_of_label)\n",
    "        elif x == 12:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 4:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 17:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 18:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 18:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 19:\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 21:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 1 or n == 10):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 22:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 15 or n == 18):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 23:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 0 or n == 4 or n == 6 or n == 8 or n == 11):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 24:\n",
    "            for n in range(0, 11):\n",
    "                if not (n == 0 or n == 7):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        elif x == 33:\n",
    "            for n in range(3, 20):\n",
    "                if not (n == 6 or n == 7 or n == 8 or n == 9 or n == 10 or n == 12 or n == 15):\n",
    "                    append_1label(label_list, labeldata, n, kind_of_label)\n",
    "        else:\n",
    "            append_label(label_list, labeldata, 20, kind_of_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ],
   "source": [
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.199635592052985\n"
     ]
    }
   ],
   "source": [
    "average = sum(label_list) / len(label_list)\n",
    "print(average)\n",
    "\n",
    "#被験者40人、覚醒度：5.247849085271323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラベルデータ取得関数(ファイル名、シート名、取得したい被験者番号、評価の種類)　（処理済みデータには使用しない）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "def get_rabel(file_name, sheet_name, subject_no, n): #n:取得したい評価の種類の列\n",
    "    w = openpyxl.load_workbook(file_name)\n",
    "    sheet = w.get_sheet_by_name(sheet_name)\n",
    "    rabel = []\n",
    "    for i in range(16 * (subject_no - 1) + 3, 16 * (subject_no - 1) + 19):\n",
    "        rabel.append(sheet.cell(row = i, column = n).value)\n",
    "    return rabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2値分類変更関数(2値分類前のラベルデータ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_2rabel(label_data):\n",
    "    label_2 = []\n",
    "    ave = sum(label_data) / len(label_data)\n",
    "    for i in range(0, len(label_data)):\n",
    "        if label_data[i] <= ave:\n",
    "            label_2.append(0)\n",
    "        else:\n",
    "            label_2.append(1)\n",
    "    return label_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成関数覚醒度のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#w=ウィンドウサイズ、s=ずらす秒数\n",
    "def create_dataset(signal_data, rabel_data, video_no, w, s, index):\n",
    "    fs = 128  # sampling周波数  \n",
    "    end_sample = len(signal_data[0][video_no][:, index])\n",
    "\n",
    "    segmentations = []\n",
    "    for idx in range(0, end_sample, int(fs*s)):\n",
    "        segment_len = fs * w  # セグメント長さ\n",
    "        segment = signal_data[0][video_no][idx:idx+(fs*w), index]  # セグメント\n",
    "        if len(segment) == segment_len:\n",
    "            segmentations.append(segment)\n",
    "\n",
    "    rabels = np.array([rabel_data[video_no]] * len(segmentations)) \n",
    "\n",
    "    return segmentations, rabels \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辞書化データセット保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def write_pickle(segmentations_data, rabels_data, file_name):\n",
    "    dataset_dic = {\n",
    "        \"x\" : segmentations_data,\n",
    "        \"y\" : rabels_data,\n",
    "    }\n",
    "    with open(\"./dataset/\" + file_name + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(dataset_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7229\n",
      "-14.156861732467481\n",
      "[[2.938568 5.       8.235496 1.       1.       1.       0.       0.\n",
      "  0.       0.       0.       0.      ]]\n",
      "3.72\n"
     ]
    }
   ],
   "source": [
    "ecgdata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "print(len(ecgdata[0][1][:, 0]))\n",
    "print(ecgdata[0][0][1][15])\n",
    "print(labeldata[0][0])\n",
    "print(labeldata[0][19][0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2値のラベル取得(ラベルデータ、平均値)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(labeldata, ave):\n",
    "    if labeldata > ave:\n",
    "        return 1\n",
    "    elif labeldata <= ave:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット取得(処理済データ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1つの動画のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def make_dataset(signaldata, labeldata, ave, segment_sec, slide, n, f, l): #(信号データ、ラベルデータ、ラベルの平均値、セグメント長、スライディングウィンドウサイズ、動画番号、取得位置、覚醒度:0感情価1) 1動画当たり\n",
    "    fs = 128 #サンプリング周波数\n",
    "    end_sample = len(signaldata[0][n][:, f]) #取得したいデータのデータの数\n",
    "    label = get_label(labeldata[0][n][0][l], ave) #平均値を閾値としたラベル取得(2値)\n",
    "    div_signals = [] #ここにセグメント分割された信号データを入れる\n",
    "\n",
    "    for idx in range(0, end_sample, int(fs * slide)): #信号データの分割\n",
    "        #mult_position = [] #取得位置を複数にしたいから\n",
    "        segment_len = fs * segment_sec #セグメントの長さ\n",
    "        for t in n:\n",
    "            \n",
    "        segment = signaldata[0][n][idx : idx + (fs * segment_sec), f] #分割された信号データ\n",
    "        #segment2 = signaldata[0][0][idx : idx + (fs * segment_sec), f + 1] #分割された信号データ\n",
    "        #mult_position.append(segment)\n",
    "        #mult_position.append(segment2)\n",
    "        if len(segment) == segment_len:\n",
    "            div_signals.append(segment) #mult_position\n",
    "    \n",
    "    labels = np.array([label] * len(div_signals))\n",
    "    return div_signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特定の一つの動画のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_specdataset(signaldata, labeldata, ave, segment, slide, f, l, n):#(信号データ、ラベルデータ、ラベルの平均値、セグメント長、スライディングウィンドウサイズ、取得位置、覚醒度:0感情価1、動画no) 1動画当たり\n",
    "    signals, labels = make_dataset(signaldata, labeldata, ave, segment, slide, n, f, l)\n",
    "    return signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1人のデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_P1dataset(signaldata, labeldata, ave, segment, slide, f, l, endno): #(信号データ、ラベルデータ、ラベルの平均値、セグメント長、スライディングウィンドウサイズ、取得位置、覚醒度:0感情価1、動画数16or20) 1動画当たり\n",
    "    signals, labels = make_dataset(signaldata, labeldata, ave, segment, slide, 0, f, l)\n",
    "    for x in range(1, endno):\n",
    "        signal, label = make_dataset(signaldata, labeldata, ave, segment, slide, x, f, l)\n",
    "        signals = np.concatenate([signals, signal])\n",
    "        labels = np.concatenate([labels, label])\n",
    "    return signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44216, 1280)\n",
      "(44216,)\n"
     ]
    }
   ],
   "source": [
    "signaldata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "signal_datas, label_datas = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "\n",
    "for x in range(2, num + 1):\n",
    "    if x < 10:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "    else:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 28 or x == 32:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 12:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 4:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 17:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 18:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 18:\n",
    "            for n in range(0, 20):\n",
    "                if not n == 19:\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 21:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 1 or n == 10):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 22:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 15 or n == 18):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 23:\n",
    "            for n in range(0, 20):\n",
    "                if not (n == 0 or n == 4 or n == 6 or n == 8 or n == 11):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 24:\n",
    "            for n in range(0, 11):\n",
    "                if not (n == 0 or n == 7):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        elif x == 33:\n",
    "            for n in range(3, 20):\n",
    "                if not (n == 6 or n == 7 or n == 8 or n == 9 or n == 10 or n == 12 or n == 15):\n",
    "                    signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "                    signal_datas = np.concatenate([signal_datas, signal])\n",
    "                    label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "\n",
    "print(signal_datas.shape)\n",
    "print(label_datas.shape)\n",
    "write_pickle(signal_datas, label_datas, \"10sproceedsubjectsP40EEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45408, 1280)\n",
      "(45408,)\n"
     ]
    }
   ],
   "source": [
    "signaldata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "signal_datas, label_datas = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "\n",
    "for x in range(2, num + 1):\n",
    "    if x < 10:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P0\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 8:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        #elif x == 9: ECGのみ\n",
    "        #    for n in range(0, 20):\n",
    "        #        if not (n == 0 or n == 1 or n == 2 or n == 5 or n == 6 or n == 8 or n == 10 or n == 11 or n == 12 or n == 14 or n == 15):\n",
    "        #            print(n)\n",
    "        #            signal, label = make_specdataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, n)\n",
    "        #            signal_datas = np.concatenate([signal_datas, signal])\n",
    "        #            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "    else:\n",
    "        signaldata = get_data(\"Data_Preprocessed_P\" + str(x), \"joined_data\")\n",
    "        labeldata = get_data(\"Data_Preprocessed_P\" + str(x), \"labels_selfassessment\")\n",
    "        if x == 24 or x == 28 or x == 32:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 16)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "        else:\n",
    "            signal, label = make_P1dataset(signaldata, labeldata, average, segment_sec, slide_sec, index, kind_of_label, 20)\n",
    "            signal_datas = np.concatenate([signal_datas, signal])\n",
    "            label_datas = np.concatenate([label_datas, label])\n",
    "\n",
    "print(signal_datas.shape)\n",
    "print(label_datas.shape)\n",
    "write_pickle(signal_datas, label_datas, \"10sproceedsubjectsP40GSR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確認用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#google colabのとき↓\n",
    "    #/content/drive/MyDrive/dataset/\n",
    "#研究室PCのとき↓\n",
    "#/Users/Ma-Lab-PC3/SatoMaho/\n",
    "\n",
    "def read_pickle(file_name):\n",
    "    with open(\"/Users/admin/卒業研究/CNN/dataset/\" + file_name + \".pickle\", \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "    return dic[\"x\"], dic[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44216, 1280)\n",
      "(45211, 1280)\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "w, z = read_pickle(\"10sproceedsubjectsP40EEG\")\n",
    "p, q = read_pickle(\"10sproceedsubjectsP40\")\n",
    "print(w.shape)\n",
    "print(p.shape)\n",
    "for x in range(0, 20):\n",
    "    print(z[x * 100], q[x * 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mread_pickle\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5sproceedsubjectsP40\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_pickle' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = read_pickle(\"5sproceedsubjectsP40\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m ecgdata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m labeldata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_selfassessment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m segmentations_datas, labels_datas \u001b[38;5;241m=\u001b[39m \u001b[43mmake_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mecgdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeldata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mfor i in range(2,6):\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mwrite_pickle(segmentations_datas, np.array(label_2), ave, \"5sproceedsubjects1-16P20\")\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m, in \u001b[0;36mmake_datasets\u001b[1;34m(signaldata, labeldata)\u001b[0m\n\u001b[0;32m     23\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labeldata[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(segmentations))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m#データを取得してリスト化\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     segmentations_data, labels_data \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m(signaldata, label_datas, \u001b[38;5;241m0\u001b[39m, segment_sec, slide_sec, index) \u001b[38;5;66;03m#最初だけ単体で作ってそこに入れてく\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#segmentations_data, labels_data = create_dataset(signaldata, label_datas_2, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m): \u001b[38;5;66;03m#動画番号\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#データセットリスト作成\n",
    "def make_datasets(signaldata, labeldata):\n",
    "    segment_sec = 5  # ウィンドウの秒数\n",
    "    slide_sec = 2.5  # ずらす秒数\n",
    "    fs = 128  # sampling周波数  \n",
    "    index = 14 #取得したいデータ\n",
    "    end_sample = len(signaldata[0][0][:, index])\n",
    "\n",
    "    label_datas = []\n",
    "\n",
    "    for i in range(0, 19):\n",
    "        label_datas.append(labeldata[0][i][0][0])\n",
    "\n",
    "    #label_datas_2 = make_2rabel(label_datas) #2値分類\n",
    "\n",
    "    segmentations = []\n",
    "    for idx in range(0, end_sample, int(fs*slide_sec)):\n",
    "        segment_len = fs * segment_sec  # セグメント長さ\n",
    "        segment = signaldata[0][0][idx:idx+(fs*segment_sec), index]  # セグメント\n",
    "        if len(segment) == segment_len:\n",
    "            segmentations.append(segment)\n",
    "\n",
    "    labels = np.array([labeldata[0]] * len(segmentations))\n",
    "#データを取得してリスト化\n",
    "    segmentations_data, labels_data = create_dataset(signaldata, label_datas, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\n",
    "    #segmentations_data, labels_data = create_dataset(signaldata, label_datas_2, 0, segment_sec, slide_sec, index) #最初だけ単体で作ってそこに入れてく\n",
    "    for i in range(1, 16): #動画番号\n",
    "        x, y = create_dataset(signaldata, label_datas, i, segment_sec, slide_sec, index)\n",
    "        #x, y = create_dataset(signaldata, label_datas_2, i, segment_sec, slide_sec, index)\n",
    "        segmentations_data = np.concatenate([segmentations_data, x])\n",
    "        labels_data = np.concatenate([labels_data, y])\n",
    "    print(len(segmentations_data), len(labels_data))\n",
    "\n",
    "    return segmentations_data, labels_data\n",
    "\n",
    "ecgdata = get_data(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "\n",
    "segmentations_datas, labels_datas = make_datasets(ecgdata, labeldata)\n",
    "\"\"\"\n",
    "for i in range(2,6):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P0\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(10,11):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(19,21):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "for i in range(25,28):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "#正規化\n",
    "def min_max(label):\n",
    "    l_min = min(label)\n",
    "    l_max = max(label)\n",
    "    return [(i - l_min) / (l_max - l_min) for i in label]\n",
    "\n",
    "scalsed_labels = min_max(labels_datas)\n",
    "#print(scalsed_labels)\n",
    "\n",
    "ave = sum(scalsed_labels) / len(scalsed_labels) #閾値\n",
    "#print(ave)\n",
    "\n",
    "label_2 = []\n",
    "for i in range(0, len(scalsed_labels)):\n",
    "    if scalsed_labels[i] <= ave:\n",
    "        label_2.append(0)\n",
    "    else:\n",
    "        label_2.append(1)\n",
    "#print(label_2)\n",
    "write_pickle(segmentations_datas, np.array(label_2), ave, \"5sproceedsubjects1-16P20\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_ldata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ecgdata \u001b[38;5;241m=\u001b[39m \u001b[43mget_ldata\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoined_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m labeldata \u001b[38;5;241m=\u001b[39m get_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData_Preprocessed_P01\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_selfassessment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m segmentations_datas, labels_datas \u001b[38;5;241m=\u001b[39m make_datasets(ecgdata, labeldata)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_ldata' is not defined"
     ]
    }
   ],
   "source": [
    "ecgdata = get_ldata(\"Data_Preprocessed_P01\", \"joined_data\")\n",
    "labeldata = get_data(\"Data_Preprocessed_P01\", \"labels_selfassessment\")\n",
    "\n",
    "segmentations_datas, labels_datas = make_datasets(ecgdata, labeldata)\n",
    "for i in range(2,3):\n",
    "    ecgdata = get_data(\"Data_Preprocessed_P0\" + str(i), \"joined_data\")\n",
    "    labeldata = get_data(\"Data_Preprocessed_P0\" + str(i), \"labels_selfassessment\")\n",
    "    x, y = make_datasets(ecgdata, labeldata)\n",
    "    segmentations_datas = np.concatenate([segmentations_datas, x])\n",
    "    labels_datas = np.concatenate([labels_datas, y])\n",
    "\n",
    "print(segmentations_datas)\n",
    "print(labels_datas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
