{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":637,"status":"ok","timestamp":1726025533088,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"VYG6UKJi0Cqd"},"outputs":[],"source":["import pickle\r\n","\r\n","#google colabのとき↓\r\n","#/content/drive/MyDrive/dataset/\r\n","#研究室PCのとき↓\r\n","#/Users/Ma-Lab-PC3/SatoMaho/\r\n","\r\n","def read_pickle(file_name):\r\n","    with open(\"/Users/admin/卒業研究/CNN/dataset/\" + file_name + \".pickle\", \"rb\") as f:\r\n","        dic = pickle.load(f)\r\n","    return dic[\"x\"], dic[\"y\"]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3.11.7 (tags/v3.11.7:fa7a6f2, Dec  4 2023, 19:24:49) [MSC v.1937 64 bit (AMD64)]\n"]}],"source":["import sys\r\n","print(sys.version)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x, y = read_pickle(\"5sproecgshort10\")\n","print(x.shape, y.shape)\n","\n","for i in range(len(x) - 1, -1, -1):\n","    if np.isnan(x[i]).any() == True:\n","        x = np.delete(x, i, axis = 0)\n","        y = np.delete(y, i)\n","\n","p = 0\n","for i in range(0, len(x)):\n","    f = 0\n","    for j in range(0, len(x[i])):\n","        if np.isnan(x[i][j]) == True:\n","            f += 1\n","    if f >= 1:\n","        p += 1\n","print(p)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x0 = 0\n","x1 = 0\n","for x in range(0, len(y)):\n","    if y[x] == 0:\n","        x0 += 1\n","    else:\n","        x1 += 1\n","print(x0, x1)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":13455,"status":"ok","timestamp":1726025550204,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"WF6VKVKu0Cqe"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","#from sklearn.model_selection import train_test_split\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys \n","sys.path.append('c:/users/admin/appdata/roaming/python/python39/site-packages') \n","import torch"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class PositionalEncoding(nn.Module):\r\n","    def __init__(self, d_model, l):\r\n","        super(PositionalEncoding, self).__init__()\r\n","        self.d_model = d_model\r\n","        pe = torch.zeros(1, l, d_model)\r\n","        for pos in range(l):\r\n","            for i in range(0, d_model, 2):\r\n","                pe[0, pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\r\n","                pe[0, pos, i + 1] = math.cos(pos / 10000 ** ((2 * (i + 1) / d_model)))\r\n","        \r\n","        self.pe = pe.unsqueeze(0)\r\n","        self.pe.requires_grad = False\r\n","\r\n","        def forward(self, x):\r\n","            ret = math.sqrt(self.d_model) * x + self.pe\r\n","            return ret"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Transformer(nn.Module):\r\n","    def __init__(self):\r\n","        super(Transformer, self).__init__()\r\n","        self.relu = nn.ReLU()\r\n","        self.conv1 = nn.Conv1d(1, 64, 33)\r\n","        self.conv2 = nn.Conv1d(64, 128, 17)\r\n","        self.conv3 = nn.Conv1d(128, 256, 9)\r\n","\r\n","        self.bn1 = nn.BatchNorm1d(64)\r\n","        self.bn2 = nn.BatchNorm1d(128)\r\n","        self.bn3 = nn.BatchNorm1d(256)\r\n","\r\n","        self.cls = nn.Parameter(torch.zeros(1, 1, 256))\r\n","\r\n","        self.positionembedding = PositionalEncoding(256, 529)\r\n","        #self.positionEmbedding = nn.Parameter(torch.zeros(1, 529, 256))\r\n","\r\n","        encoderLayer = nn.TransformerEncoderLayer(d_model = 256, nhead = 8, dropout = 0.2, batch_first = True)\r\n","        self.encoder = nn.TransformerEncoder(encoderLayer, num_layers = 2)\r\n","\r\n","        self.linear = nn.Linear(256, 2)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.bn1(self.conv1(x))\r\n","        x = self.relu(x)\r\n","        x = self.conv2(x)\r\n","        x = self.relu(x)\r\n","        x = self.bn2(self.conv3(x))\r\n","        x = self.relu(x)\r\n","        x = torch.transpose(x, 2, 1)\r\n","        clsToken = self.cls.repeat_interleave(x.shape[0], dim = 0)\r\n","        x = torch.cat((clsToken, x), dim = 1)\r\n","        x = self.positionembedding(x)\r\n","        x = self.encoder(x)\r\n","        x = self.linear(x[:, 0, :])\r\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class TransformerECG(nn.Module):\r\n","    def __init__(self):\r\n","        super(TransformerECG, self).__init__()\r\n","        self.relu = nn.ReLU()\r\n","        self.maxpool1 = nn.MaxPool1d(2)\r\n","        self.conv1 = nn.Conv1d(1, 64, 33) #65 33\r\n","        self.conv2 = nn.Conv1d(64, 128, 17) #33 17\r\n","        self.conv3 = nn.Conv1d(128, 256, 9) #17 9\r\n","        #self.dropout1 = nn.Dropout(0.3)\r\n","        self.bn1 = nn.BatchNorm1d(64)\r\n","        self.bn2 = nn.BatchNorm1d(128)\r\n","        self.bn3 = nn.BatchNorm1d(256)\r\n","        self.cls = nn.Parameter(torch.zeros(1, 1, 256))\r\n","        self.positionembedding = PositionalEncoding(256, 297) #1241, 601, 561\r\n","        encoderLayer = nn.TransformerEncoderLayer(d_model = 256, nhead = 2, dropout = 0.1, batch_first = True)\r\n","        self.encoder = nn.TransformerEncoder(encoderLayer, num_layers = 2)\r\n","        self.maxpool2 = nn.MaxPool1d(2, ceil_mode = True)\r\n","        self.linear1 = nn.Linear(128, 512)\r\n","        self.linear2 = nn.Linear(512, 2)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = self.relu(x)\r\n","        x = self.bn1(x)\r\n","        x = self.maxpool1(x)\r\n","        x = self.conv2(x)\r\n","        x = self.relu(x)\r\n","        x = self.bn2(x)\r\n","        x = self.maxpool1(x)\r\n","        x = self.conv3(x)\r\n","        x = self.relu(x)\r\n","        x = self.bn3(x)\r\n","        x = torch.transpose(x, 2, 1)\r\n","        clsToken = self.cls.expand(x.size(0), -1, -1) #clsToken = self.cls.repeat_interleave(x.shape[0], dim = 0)\r\n","        x = torch.cat((clsToken, x), dim = 1)\r\n","        x = self.positionembedding(x)\r\n","        x = self.encoder(x)\r\n","        x = self.maxpool2(x[:, 0, :])\r\n","        x = self.linear1(x)\r\n","        #x = self.dropout1(x)\r\n","        x = self.linear2(x)\r\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":521,"status":"ok","timestamp":1726029591757,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"89iMXMda0Cqf"},"outputs":[],"source":["class CNN(nn.Module):\r\n","    def __init__(self):\r\n","        super(CNN, self).__init__()\r\n","        self.pool = nn.MaxPool1d(2)\r\n","        self.relu = nn.ReLU()\r\n","\r\n","        self.dropout = nn.Dropout(0.4)\r\n","\r\n","        self.conv1 = nn.Conv1d(1, 64, 17)\r\n","        self.conv2 = nn.Conv1d(64, 128, 17)\r\n","        self.conv3 = nn.Conv1d(128, 256, 17)\r\n","\r\n","        self.bn1 = nn.BatchNorm1d(64)\r\n","        self.bn2 = nn.BatchNorm1d(128)\r\n","        self.bn3 = nn.BatchNorm1d(256)\r\n","\r\n","        self.fc1 = nn.Linear(16896, 256)\r\n","        self.fc2 = nn.Linear(256, 64)\r\n","        self.fc3 = nn.Linear(64, 2)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.bn1(self.conv1(x))\r\n","        x = self.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.bn2(self.conv2(x))\r\n","        x = self.relu(x)\r\n","        x = self.pool(x)\r\n","        x = self.bn3(self.conv3(x))\r\n","        x = self.relu(x)\r\n","        x = self.pool(x)\r\n","        x = x.view(x.size(0), -1)\r\n","        x = self.relu(self.fc1(x))\r\n","        x = self.dropout(x)\r\n","        x = self.relu(self.fc2(x))\r\n","        x = self.dropout(x)\r\n","        x = self.fc3(x)\r\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":514,"status":"ok","timestamp":1726025592175,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"fhXIbAUF0Cqf"},"outputs":[],"source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, label, transform = None):\n","        self.transform = transform\n","        self.data = data\n","        self.data_num = len(data)\n","        self.label = label\n","\n","    def __len__(self):\n","        return self.data_num\n","\n","    def __getitem__(self, idx):\n","        if self.transform:\n","            out_data = self.transform(self.data)[0][idx]\n","            out_label = self.label[idx]\n","        else:\n","            out_data = self.data[idx]\n","            out_label = self.label[idx]\n","        return out_data, out_label"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import math"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["n = TransformerECG()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from torchsummary import summary"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torchsummary\\torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 140\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[9], line 22\u001b[0m, in \u001b[0;36mTransformerECG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1790\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1788\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1790\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [2, 64, 1, 1280]","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\.virtualenvs\\Calc-8reO6iWN\\Lib\\site-packages\\torchsummary\\torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    142\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(executed_layers)\n\u001b[0;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: []"]}],"source":["summary(n, (, 1, 1280))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x, y = read_pickle(\"5sproceedsubjectsP1\")\r\n","print(x.shape)\r\n","transform = transforms.Compose([transforms.ToTensor()])\r\n","dataset = MyDataset(x, y, transform) #dataset[?][0]生体データ、dataset[?][1]ラベル\r\n","print(len(dataset[0]))\r\n","r = 0.7\r\n","train_size = int(len(dataset) * r)\r\n","test_size = len(dataset) - train_size\r\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\r\n","print(len(test_dataset))\r\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = 4, shuffle = True, drop_last = True)\r\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 2, shuffle = True, drop_last = True)\r\n","print(len(test_dataloader.dataset))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## google colabのときのみ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3371,"status":"ok","timestamp":1726027255875,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"bs4Qaq5616qt","outputId":"566b5af2-1416-47b9-fa96-1f01a696f32a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":740,"status":"ok","timestamp":1726029596564,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"rlf01AVQ0Cqg"},"outputs":[],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n","net = CNN()\r\n","net = net.to(device)\r\n","loss_fn = nn.CrossEntropyLoss()\r\n","optimizer = optim.Adam(net.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1726029073804,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"8cPMWUKO0Cqg"},"outputs":[],"source":["def train(dataloader, epoch, model, criterion, optimizer):\n","  size = len(dataloader.dataset)\n","  for e in range(epoch):\n","      train_loss_sum = 0\n","      train_acc_sum = 0\n","      val_loss_sum = 0\n","      val_acc_sum = 0\n","      model.train()\n","      for batch, (x, y) in enumerate(dataloader):\n","        x = x.unsqueeze(1)\n","        x, y = x.to(device, dtype = torch.float32), y.to(device, dtype = torch.long)\n","\n","        optimizer.zero_grad()\n","        pred = model(x)\n","        #print(pred)\n","        loss = loss_fn(pred, y)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss_sum += loss.item()\n","        pred = pred.argmax(1)\n","        train_acc_sum += pred.eq(y.view_as(pred)).sum().item()\n","\n","      \"\"\"model.eval()\n","      with torch.no_grad():\n","        for x, y in test_dataloader:\n","          x = x.unsqueeze(1)\n","          x, y = x.to(device, dtype = torch.float32), y.to(device, dtype = torch.long)\n","          pred = model(x)\n","          val_loss_sum += loss_fn(pred, y).item()\n","          pred = pred.argmax(1)\n","          val_acc_sum += pred.eq(y.view_as(pred)).sum().item()\"\"\"\n","\n","      train_loss = train_loss_sum / len(dataloader)\n","      train_acc = train_acc_sum / train_size\n","      #val_loss = val_loss_sum / len(dataloader)\n","      #val_acc = val_acc_sum / test_size\n","      train_loss_list.append(train_loss)\n","      train_acc_list.append(train_acc)\n","      #val_loss_list.append(val_loss)\n","      #val_acc_list.append(val_acc)\n","      print(f\"{e + 1} / {epoch} | Train Loss : {train_loss}, Acc : {100 * train_acc}\")#, Val Loss : {val_loss}, Acc : {100 * val_acc}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":460,"status":"ok","timestamp":1726029098595,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"Eh4NRhyj0Cqg"},"outputs":[],"source":["def test(dataloader, model, loss_fn):\n","    model.eval()\n","    correct = 0\n","    test_loss = 0\n","    with torch.no_grad():\n","        for x, y in dataloader:\n","            x = x.unsqueeze(1)\n","            x, y = x.to(device, dtype = torch.float32), y.to(device, dtype = torch.long)\n","            pred = model(x)\n","            test_loss += loss_fn(pred, y).item()\n","            pred = pred.argmax(1)\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","    print(f\"Loss : {test_loss / len(dataloader)}, Accuracy : {100 * correct / test_size}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339944,"status":"ok","timestamp":1726029941831,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"0sQWIn2f0Cqg","outputId":"23fee3a2-4e79-4e47-f6ca-d85d45cc21bc"},"outputs":[],"source":["epochs = 30\r\n","train_loss_list = []\r\n","train_acc_list = []\r\n","val_loss_list = []\r\n","val_acc_list = []\r\n","train(train_dataloader, epochs, net, loss_fn, optimizer)\r\n","test(test_dataloader, net, loss_fn)\r\n","print(\"Done!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":795,"status":"ok","timestamp":1726029960170,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"uuamSAB5S0Mp","outputId":"a9fd4ed9-fa4f-4c96-bf78-4df03a5f56cb"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_acc_list, label='Train Accuracy')\n","plt.plot(val_acc_list, label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1726029966312,"user":{"displayName":"佐藤茉帆","userId":"02533179973160754332"},"user_tz":-540},"id":"NbG5XbmUTAe7","outputId":"39f9333c-bcdb-4efa-d557-1fae94b075b7"},"outputs":[],"source":["plt.plot(train_loss_list, label='Train Loss')\n","plt.plot(val_loss_list, label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]\n"]}],"source":["import sys\r\n","print(sys.version)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3.11.7 64-bit ('Calc-8reO6iWN')","metadata":{"interpreter":{"hash":"19ac16ba4cfb3d4ea2ea72e3df8fbc1beda1c53d01be299bec44f61ddc76066d"}},"name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}